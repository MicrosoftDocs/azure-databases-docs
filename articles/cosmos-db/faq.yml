### YamlMime:FAQ
metadata:
  title: Frequently asked questions
  titleSuffix: Azure Cosmos DB
  description: Get answers to frequently asked questions about Azure Cosmos DB. Learn about capacity, performance levels, and scaling, and service features.
  author: markjbrown
  ms.author: mjbrown
  ms.service: azure-cosmos-db
  ms.topic: faq
  ms.date: 09/03/2025
  applies-to:
    - ✅ NoSQL
    - ✅ MongoDB
    - ✅ Apache Cassandra
    - ✅ Apache Gremlin
    - ✅ Table
title: Frequently asked questions about Azure Cosmos DB
summary: |
  [!INCLUDE[NoSQL, MongoDB, Cassandra, Gremlin, Table](includes/appliesto-nosql-mongodb-cassandra-gremlin-table.md)]
sections:
  - name: General
    questions:
      - question: |
          What are the typical use cases for Azure Cosmos DB?
        answer: |
          Azure Cosmos DB is well suited for web, mobile, gaming, and IoT use cases. In these use cases; automatic scale, predictable performance, fast order of millisecond response times, and the ability to query over schema-free data is important. Azure Cosmos DB lends itself to rapid development and supporting the continuous iteration of application data models. Applications that manage user-generated content and data often map to [common use cases for Azure Cosmos DB](use-cases.md).
      - question: |
          How does Azure Cosmos DB offer predictable performance?
        answer: |
          A [request unit](request-units.md) (RU) is the measure of throughput in Azure Cosmos DB. A single request unit throughput corresponds to the throughput of the `GET` HTTP action for a 1-kilobite document. Every operation in Azure Cosmos DB; including reads, writes, queries, and stored procedure executions; has a deterministic request unit value based on the throughput required to complete the operation. Instead of being forced to consider CPU, IO, and memory in relation to your application throughput, you can think in terms of request units.

          You can configure each Azure Cosmos DB container with provisioned throughput in terms of request units per second (RU/s). You can benchmark individual requests to measure in request units, and create a container to handle the sum of request units across all requests for that container in a second. You can also scale up or scale down your container's throughput as the needs of your application evolve. For more information on how to measure request units, see the [throughput calculator](https://cosmos.azure.com/capacitycalculator).
      - question: |
          How does Azure Cosmos DB support various data models such as key/value, columnar, document, and graph?
        answer: |
          Key/value (table), columnar, document, and graph data models are all natively supported because of the ARS (atoms, records, and sequences) design that Azure Cosmos DB is built on. Atoms, records, and sequences can be easily mapped and projected to various data models. The APIs for a subset of models are available using the ARS design (MongoDB RU, NoSQL, Table, Apache Cassandra, and Apache Gremlin). Azure Cosmos DB also supports other APIs such as MongoDB vCore, Cassandra MI, or PostgreSQL.
      - question: |
          What is an Azure Cosmos DB container?
        answer: |
          A container is a group of items. Containers can span one or more partitions and can scale to handle practically unlimited volumes of storage or throughput.

          | | Containers known as |
          | --- | --- |
          | **Azure Cosmos DB for NoSQL** | Container |
          | **Azure Cosmos DB for MongoDB RU** | Collection |
          | **Azure Cosmos DB for MongoDB vCore** | Collection |
          | **Azure Cosmos DB for Apache Cassandra** | Table |
          | **Azure Cosmos DB for Apache Gremlin** | Graph |
          | **Azure Cosmos DB for Table** | Table |

          A container is a billable entity, where the throughput and used storage determines the cost. Each container is billed hourly, based on the provisioned throughput and used storage space. For more information, see [Azure Cosmos DB pricing](https://azure.microsoft.com/pricing/details/cosmos-db/).
      - question: |
          Can I use multiple APIs to access my data?
        answer: |
          Azure Cosmos DB is Microsoft's globally distributed, multi-model database service. Multi-model refers to Azure Cosmos DB's support for multiple APIs and data models. In this paradigm, different APIs use different data formats for storage and wire protocol. For example; NoSQL uses JSON, MongoDB uses binary-encoded JSON (BSON), Table uses Entity Data Model (EDM), Cassandra uses Cassandra Query Language (CQL), Gremlin uses JSON format. As a result, we recommend using the same API for all access to the data in a given account.
      - question: |
          Can I integrate Azure Cosmos DB directly with other services?
        answer: |
          Yes. Azure Cosmos DB APIs allow direct integration. For example, the Azure Cosmos DB REST APIs can be integrated with Azure API Management for CRUD operations, eliminating the need for intermediate services like Azure Functions.
      - question: |
          Is Azure Cosmos DB HIPAA compliant?
        answer: |
          Yes, Azure Cosmos DB is HIPAA-compliant. HIPAA establishes requirements for the use, disclosure, and safeguarding of individually identifiable health information. For more information, see the [Microsoft Trust Center](/compliance/regulatory/offering-hipaa-hitech).
      - question: |
          What are the storage limits of Azure Cosmos DB?
        answer: |
          There's no limit to the total amount of data that a container can store in Azure Cosmos DB.
      - question: |
          What are the throughput limits of Azure Cosmos DB?
        answer: |
          There's no limit to the total amount of throughput that a container can support in Azure Cosmos DB. The key idea is to distribute your workload roughly even among a sufficiently large number of partition keys.
      - question: |
          Are direct and gateway connectivity modes encrypted?
        answer: |
          Yes both modes are always fully encrypted.
      - question: |
          How much does Azure Cosmos DB cost?
        answer: |
          The number of provisioned containers, number of hours containers were online, and the provisioned throughput for each container determines Azure Cosmos DB usage charges. For more pricing details, refer to [Azure Cosmos DB pricing](https://azure.microsoft.com/pricing/details/cosmos-db/).
      - question: |
          How can I get extra help with Azure Cosmos DB?
        answer: |
          To ask a technical question, you can post to one of these two question and answer forums:

          - [Microsoft Question & Answers (Q&A)](/answers/topics/azure-cosmos-db.html)
          - [Stack Overflow](https://stackoverflow.com/questions/tagged/azure-cosmosdb). Stack Overflow is best for programming questions. [Provide as many details as possible, making the question clear and answerable](https://stackoverflow.com/help/how-to-ask).

          To fix an issue with your account, file a [support request](https://portal.azure.com/#blade/Microsoft_Azure_Support/HelpAndSupportBlade/newsupportrequest) in the Azure portal.
  - name: Migrating Azure Cosmos DB Accounts across different resource groups, subscriptions, and tenants
    questions:
      - question: |
          How do I migrate an Azure Cosmos DB account to a different resource group or to a different subscription?
        answer: |
          The general guideline to migrate a Cosmos DB account to a different resource group or subscription is described in the [moving Azure resources to a new resource group or subscription](/azure/azure-resource-manager/management/move-resource-group-and-subscription) article.

          After you successfully move the Azure Cosmos DB account per the general guideline, any identities (System-Assigned or User-Assigned) associated with the account must be [reassigned](/azure/cosmos-db/how-to-setup-managed-identity). This reassignment is required in order to ensure that these identities continue to have the necessary permissions to access the Key Vault key.
          > [!WARNING]
          > If your Cosmos DB account has Customer Managed Keys enabled, you can only migrate the account to a different resource group or subscription if it's in an Active state. Accounts in a Revoked state can't be migrated.
      - question: |
          How do I migrate an Azure Cosmos DB account to a different tenant?
        answer: |
          If your Cosmos DB account has Customer Managed Keys enabled, you can only migrate the account if it's a cross-tenant customer-managed key account. For more information, see the guide on [configuring cross-tenant customer-managed keys for your Azure Cosmos DB account with Azure Key Vault](/azure/cosmos-db/how-to-setup-cross-tenant-customer-managed-keys?tabs=azure-portal).
          > [!WARNING]
          > After migrating, it's crucial to keep the Azure Cosmos DB account and the Azure Key Vault in separate tenants to preserve the original cross-tenant relationship. Ensure the Key Vault key remains in place until the Cosmos DB account migration is complete.
  - name: Migrating to continuous backup mode
    questions:
      - question: |
          What should I expect during and after migration?
        answer: |
          When migrating from periodic mode to continuous mode, you can't run any control plane operations that performs account level updates or deletes. For example, operations such as adding or removing regions, account failover, updating backup policy etc. can't be run while the migration is in progress. The time for migration depends on the size of data and the number of regions in your account. Restore action on the migrated accounts only succeeds from the time when migration successfully completes.

          You can restore your account after the migration completes. If the migration completes at 1:00 PM PST, you can do point in time restore starting from 1:00 PM PST.
      - question: |
          Does the migration only happen at the account level?
        answer: |
          Yes.
      - question: |
          Which accounts can be targeted for backup migration for continuous backup?
        answer: |
          API for NoSQL, API for Table, Gremlin API, and API for MongoDB accounts that use shared, provisioned, or autoscale provisioned throughput support migration to continuous backup.

          Accounts with Azure Synapse Link enabled, or that had Azure Synapse Link disabled for one or more collections, can't migrate to continuous backup.
      - question: |
          Does the migration take time? What is the typical time?
        answer: |
          Migration takes a varying amount of time that largely depends on the size of data and the number of regions in your account. You can get the migration status using Azure CLI or PowerShell commands. For large accounts with tens of terabytes of data, the migration can take up to few days to complete.
      - question: |
          Does the migration for multi region write(mrw) account with periodic backup to multi region write with continuous backup take time?
        answer: |
          Yes, this migration takes time that largely depends on need to wait for all old tentative writes to get drained during continuous backup migration. You can get the migration status using Azure CLI or PowerShell commands. For large accounts with tens of terabytes of data, the migration can take up to few days to complete.
      - question: |
          Does the migration cause any availability downtime?
        answer: |
          No, the migration operation takes place in the background. So, client requests aren't affected. However, we need to perform some backend operations during the migration, and it could take extra time if the account is under heavy load.
      - question: |
          What happens if the migration fails? Do I still get periodic backups or continuous backups?
        answer: |
          Once the migration process is started, the account is enabled in continuous mode. If the migration fails, you must initiate migration again until it succeeds.
      - question: |
          How do I perform a restore to a timestamp before/during/after the migration?
        answer: |
          Assume that you started migration at ``t1`` and finished at ``t5``, you can't use a restore timestamp between ``t1`` and ``t5``.
          Also assume that your account is now in continuous mode. To restore to a time after ``t5``, perform the restore using Azure portal, CLI, or PowerShell like normally with a continuous account. This self-service restore request can only be done after the migration is complete.
          To restore to a time before ``t1``, you can open a support ticket like you normally would with a periodic backup account. After the migration, you have up to 30 days to perform the periodic restore. During these 30 days, you can restore based on the backup retention/interval of your account before the migration. For example, if the backup was configured to retain 24 copies at 1 hour intervals, then you can restore anytime between `(t1 – 24 hours)` and `t1`.
      - question: |
          Which account level control plane operations are blocked during migration?
        answer: |
          Operations such as add/remove region, failover, changing backup policy, and any throughput changes resulting in data movement are blocked during migration.
      - question: |
          If the migration fails for some underlying issue, does it block the control plane operation until you retry and complete migration successfully?
        answer: |
          Failed migration doesn't block any control plane operations. If migration fails, retry until it succeeds before performing other control plane operations.
      - question: |
          Is it possible to cancel the migration?
        answer: |
          It isn't possible to cancel the migration because migrations aren't a reversible operation. Via support call team can cancel temporarily and let the offline operations continue. But one can't move back to periodic backup state.
      - question: |
          Is there a tool that can help estimate migration time based on the data usage and number of regions?
        answer: |
          There isn't a tool to estimate time. Our testing and scale runs indicate that an account with 1 TB of data takes roughly 90 minutes.
          For multi-region accounts, calculate the total data size as ``Number_of_regions * Data_in_single_region``.
      - question: |
          Since the continuous backup mode is now GA, do you still recommend restoring a copy of your account? Would you recommend trying migration on the copy before deciding to migrate the production account?
        answer: |
          Test the continuous backup mode feature to verify it works as expected before migrating production accounts. Migration is a one-way operation and can't be reversed.
  - name: Try Azure Cosmos DB free
    questions:
      - question: |
          Is a free account available?
        answer: |
          Yes, you can sign up for a [free database account](free-tier.md) with 1,000 RU/sec and 25GB for free.

          If you're new to Azure, you can sign up for an [Azure free account](https://azure.microsoft.com/pricing/purchase-options/azure-account?cid=msft_learn), which gives you 30 days and a credit to try all the Azure services. If you have a Visual Studio subscription, you're also eligible for [free Azure credits](https://azure.microsoft.com/pricing/member-offers/msdn-benefits-details/) to use on any Azure service.

          You can also use the [Azure Cosmos DB Emulator](emulator.md) to develop and test your application locally for free, without creating an Azure subscription. When you're satisfied with how your application is working in the Azure Cosmos DB Emulator, you can switch to using an Azure Cosmos DB account in the cloud.
  - name: Get started with Azure Cosmos DB
    questions:
      - question: |
          How do I sign up for Azure Cosmos DB?
        answer: |
          Azure Cosmos DB is available in the Azure portal. First, sign up for an Azure subscription. After you sign up, add an Azure Cosmos DB account to your Azure subscription.
      - question: |
          How do I authenticate to Azure Cosmos DB?
        answer: |
          Use Microsoft Entra ID to authenticate to Azure Cosmos DB for all APIs that support this method of authentication. For APIs that don't support Microsoft Entra ID authentication, use the keys with caution. Ensure that keys for production accounts are stored securely, such as in Azure Key Vault.
      - question: |
          Where is Azure Cosmos DB available?
        answer: |
          For information about regional availability for Azure Cosmos DB, see [Azure products available by region](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?products=cosmos-db). You can account your database to one or more of these regions.

          The software development kits (SDKs) for Azure Cosmos DB allow configuration of the regions they use for connections. In most SDKs, the `PreferredLocations`` value is set to any of the Azure regions in which Azure Cosmos DB is available.
      - question: |
          Is there anything I should be aware of when distributing data across the world via the Azure datacenters?
        answer: |
          Azure Cosmos DB is present across all Azure regions, as specified on the [Azure regions](https://azure.microsoft.com/regions/) page. Because it's a core Azure service, every new datacenter has an Azure Cosmos DB presence.

          When you set a region, remember that Azure Cosmos DB respects sovereign and government clouds. For example, you can't replicate data out of a [sovereign region](https://azure.microsoft.com/global-infrastructure/). Similarly, you can't enable replication into other sovereign locations from an outside account.
      - question: |
          Is it possible to switch between container-level and database-level throughput provisioning?
        answer: |
          Container and database-level throughput provisioning are separate offerings and switching between either of these offerings require migrating data from source to destination. You need to create a new database or container and then migrate data using [bulk executor library](bulk-executor-overview.md) or [Azure Data Factory](/azure/data-factory/connector-azure-cosmos-db).
      - question: |
          Does Azure Cosmos DB support time series analysis?
        answer: |
          Yes, Azure Cosmos DB supports time series analysis. You can use the change feed to build aggregated views over time series data. You can extend this approach by using Apache Spark streaming or another stream data processor.
      - question: |
          What are the Azure Cosmos DB service quotas and throughput limits?
        answer: |
          For information about service quotas and throughput limits, see [service quotas](concepts-limits.md) and [throughout limits](set-throughput.md#comparison-of-models).
additionalContent: |
  ## Related content

  - Frequently asked questions about [Azure Cosmos DB for NoSQL](nosql/faq.yml)
  - Frequently asked questions about [Azure Cosmos DB for MongoDB](mongodb/faq.yml)
  - Frequently asked questions about [Azure Cosmos DB for Apache Gremlin](gremlin/faq.yml)
  - Frequently asked questions about [Azure Cosmos DB for Apache Cassandra](cassandra/faq.yml)
  - Frequently asked questions about [Azure Cosmos DB for Table](table/faq.yml)
